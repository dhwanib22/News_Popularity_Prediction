{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Topic: Sentiment Analysis**\n",
        "---"
      ],
      "metadata": {
        "id": "p9D9dimrXxSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Connecting to drive**\n",
        "---\n"
      ],
      "metadata": {
        "id": "LsdbJ0vzmsU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOXxdToTmVa8",
        "outputId": "cbd2aa42-e869-442b-da3c-4c0db224500f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Mount your Google Drive to access files stored there\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Replace 'your_file_name.csv' with the actual name of your file.\n",
        "file_name = 'final_data.csv'\n",
        "\n",
        "# Set the root directory to your Google Drive\n",
        "root_dir = '/content/drive/My Drive/'\n",
        "\n",
        "# Function to recursively search for the file in all directories and subdirectories\n",
        "def find_file(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        item_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(item_path) and item == file_name:\n",
        "            return directory\n",
        "        elif os.path.isdir(item_path):\n",
        "            result = find_file(item_path)\n",
        "            if result:\n",
        "                return result\n",
        "    return None\n",
        "\n",
        "# Call the function to find the file directory\n",
        "file_directory = find_file(root_dir)\n",
        "\n",
        "# Print the file directory\n",
        "if file_directory:\n",
        "    print(\"File directory:\", file_directory)\n",
        "else:\n",
        "    print(\"File not found in Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgoQfuZimgaY",
        "outputId": "e7505da7-d904-4578-d59b-6d30e95fb4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File directory: /content/drive/My Drive/AI_Desicion_Scineces2_endterm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/My Drive/AI_Desicion_Scineces2_endterm')"
      ],
      "metadata": {
        "id": "7hwxTx-Mmpud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing required Libraries**\n",
        "---"
      ],
      "metadata": {
        "id": "Ast8XmSym1sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM,Dense, SpatialDropout1D, Dropout\n",
        "from keras.initializers import Constant\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "Add3-Hr9m5CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Reading the final dataset**\n",
        "---"
      ],
      "metadata": {
        "id": "FiZ0rAxrm-qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file and convert it to DataFrame\n",
        "df = pd.read_csv('final_data.csv')"
      ],
      "metadata": {
        "id": "b2oOU696m8m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "VDabIuRLnOJO",
        "outputId": "f977684b-9d04-4d4f-980a-fe1647b6112d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    IDLink                                             Title  \\\n",
              "0  80690.0                               Monday, 29 Feb 2016   \n",
              "1  28854.0      Buffett: Politicians 'Dead Wrong' on Economy   \n",
              "2  81052.0                               Monday, 29 Feb 2016   \n",
              "3  80994.0                               Tuesday, 1 Mar 2016   \n",
              "4    946.0  Microsoft Takes Six Billion Dollars From Android   \n",
              "\n",
              "                                            Headline      Topic PublishDate  \\\n",
              "0  RAMALLAH, February 25, 2016 (WAFA) - Palestine...  palestine  2016-02-28   \n",
              "1  Warren Buffett has a message for presidential ...    economy  2016-02-28   \n",
              "2  RAMALLAH, February 29, 2016 (WAFA) - The Gover...  palestine  2016-03-01   \n",
              "3  RAMALLAH, February 29, 2016 (WAFA) - The Gover...  palestine  2016-03-01   \n",
              "4  A long time ago, Microsoft MSFT +0.00% purchas...  microsoft  2015-11-01   \n",
              "\n",
              "   SentimentTitle  SentimentHeadline  Facebook  GooglePlus  LinkedIn  \\\n",
              "0        0.000000          -0.005906       1.0         1.0       1.0   \n",
              "1        0.051031          -0.037921       0.0         0.0       0.0   \n",
              "2        0.000000           0.048546       1.0         1.0       1.0   \n",
              "3       -0.243068           0.048546       1.0         1.0       1.0   \n",
              "4        0.000000           0.115928       0.0         0.0       0.0   \n",
              "\n",
              "  PublishTime  Weekday  Facebook_scaled  GooglePlus_scaled  LinkedIn_scaled  \\\n",
              "0    14:03:00   Sunday         -0.64969          -0.617774        -0.563154   \n",
              "1    19:17:00   Sunday          0.00000           0.000000         0.000000   \n",
              "2    09:29:00  Tuesday         -0.64969          -0.617774        -0.563154   \n",
              "3    00:15:00  Tuesday         -0.64969          -0.617774        -0.563154   \n",
              "4    00:00:00   Sunday          0.00000           0.000000         0.000000   \n",
              "\n",
              "  SentimentTitle_Category SentimentHeadline_Category Source_type  Hour  \n",
              "0                 neutral                   negative           D    14  \n",
              "1                positive                   negative           D    19  \n",
              "2                 neutral                   positive           D     9  \n",
              "3                negative                   positive           D     0  \n",
              "4                 neutral                   positive           D     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb4f96a6-eef1-41c8-917a-5462be3d97bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDLink</th>\n",
              "      <th>Title</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Topic</th>\n",
              "      <th>PublishDate</th>\n",
              "      <th>SentimentTitle</th>\n",
              "      <th>SentimentHeadline</th>\n",
              "      <th>Facebook</th>\n",
              "      <th>GooglePlus</th>\n",
              "      <th>LinkedIn</th>\n",
              "      <th>PublishTime</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>Facebook_scaled</th>\n",
              "      <th>GooglePlus_scaled</th>\n",
              "      <th>LinkedIn_scaled</th>\n",
              "      <th>SentimentTitle_Category</th>\n",
              "      <th>SentimentHeadline_Category</th>\n",
              "      <th>Source_type</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>80690.0</td>\n",
              "      <td>Monday, 29 Feb 2016</td>\n",
              "      <td>RAMALLAH, February 25, 2016 (WAFA) - Palestine...</td>\n",
              "      <td>palestine</td>\n",
              "      <td>2016-02-28</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.005906</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14:03:00</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>-0.64969</td>\n",
              "      <td>-0.617774</td>\n",
              "      <td>-0.563154</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "      <td>D</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28854.0</td>\n",
              "      <td>Buffett: Politicians 'Dead Wrong' on Economy</td>\n",
              "      <td>Warren Buffett has a message for presidential ...</td>\n",
              "      <td>economy</td>\n",
              "      <td>2016-02-28</td>\n",
              "      <td>0.051031</td>\n",
              "      <td>-0.037921</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19:17:00</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "      <td>D</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>81052.0</td>\n",
              "      <td>Monday, 29 Feb 2016</td>\n",
              "      <td>RAMALLAH, February 29, 2016 (WAFA) - The Gover...</td>\n",
              "      <td>palestine</td>\n",
              "      <td>2016-03-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048546</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>09:29:00</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>-0.64969</td>\n",
              "      <td>-0.617774</td>\n",
              "      <td>-0.563154</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "      <td>D</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80994.0</td>\n",
              "      <td>Tuesday, 1 Mar 2016</td>\n",
              "      <td>RAMALLAH, February 29, 2016 (WAFA) - The Gover...</td>\n",
              "      <td>palestine</td>\n",
              "      <td>2016-03-01</td>\n",
              "      <td>-0.243068</td>\n",
              "      <td>0.048546</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>00:15:00</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>-0.64969</td>\n",
              "      <td>-0.617774</td>\n",
              "      <td>-0.563154</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>946.0</td>\n",
              "      <td>Microsoft Takes Six Billion Dollars From Android</td>\n",
              "      <td>A long time ago, Microsoft MSFT +0.00% purchas...</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2015-11-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>00:00:00</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb4f96a6-eef1-41c8-917a-5462be3d97bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb4f96a6-eef1-41c8-917a-5462be3d97bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb4f96a6-eef1-41c8-917a-5462be3d97bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b62c5e89-6c99-4ec8-8b87-02745f172b22\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b62c5e89-6c99-4ec8-8b87-02745f172b22')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b62c5e89-6c99-4ec8-8b87-02745f172b22 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3-MonlZnPRL",
        "outputId": "8d9bdf03-9d03-4a99-ca10-1c7d65e4abac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(92808, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBqvX1ifnTEa",
        "outputId": "d9c27189-d83c-46ca-a328-9f87465c5d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 92808 entries, 0 to 92807\n",
            "Data columns (total 19 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   IDLink                      92808 non-null  float64\n",
            " 1   Title                       92808 non-null  object \n",
            " 2   Headline                    92808 non-null  object \n",
            " 3   Topic                       92808 non-null  object \n",
            " 4   PublishDate                 92808 non-null  object \n",
            " 5   SentimentTitle              92808 non-null  float64\n",
            " 6   SentimentHeadline           92808 non-null  float64\n",
            " 7   Facebook                    92808 non-null  float64\n",
            " 8   GooglePlus                  92808 non-null  float64\n",
            " 9   LinkedIn                    92808 non-null  float64\n",
            " 10  PublishTime                 92808 non-null  object \n",
            " 11  Weekday                     92808 non-null  object \n",
            " 12  Facebook_scaled             92808 non-null  float64\n",
            " 13  GooglePlus_scaled           92808 non-null  float64\n",
            " 14  LinkedIn_scaled             92808 non-null  float64\n",
            " 15  SentimentTitle_Category     92808 non-null  object \n",
            " 16  SentimentHeadline_Category  92808 non-null  object \n",
            " 17  Source_type                 92808 non-null  object \n",
            " 18  Hour                        92808 non-null  int64  \n",
            "dtypes: float64(9), int64(1), object(9)\n",
            "memory usage: 13.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing**\n",
        "----\n",
        "\n",
        "- Cleaning the text column ('reviewText') by:\n",
        "- Removing stop words\n",
        "- Convert text to lowercase\n",
        "- Removing punctuations and numbers\n",
        "- Tokenizing\n",
        "- Stemming and\n",
        "- Lemmatization"
      ],
      "metadata": {
        "id": "dTJYyaoSn2_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import nltk\n",
        "import re"
      ],
      "metadata": {
        "id": "EuaL3uxwoFLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1jc1OJsoIaY",
        "outputId": "eb3ad86f-0fce-4b2d-9635-4b9322835d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Define stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Define lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "\n",
        "    # Tokenize and remove stop words\n",
        "    tokenized_text = [w for w in word_tokenize(text) if w not in stop_words]\n",
        "    text = ' '.join(tokenized_text)\n",
        "\n",
        "    # Perform stemming and lemmatization\n",
        "    stemmed_lemmatized_text = [stemmer.stem(lemmatizer.lemmatize(w)) for w in word_tokenize(text)]\n",
        "    text = ' '.join(stemmed_lemmatized_text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "Ulu3LM25oIPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title_headline'] = df['Title'] + ' ' + df['Headline']"
      ],
      "metadata": {
        "id": "RTG-N6O8iOkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title_headline'] = df['title_headline'].apply(preprocess_text)\n",
        "df['Headline'] = df['Headline'].apply(preprocess_text)\n",
        "df['Title'] = df['Title'].apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3WYsW9ZoIEt",
        "outputId": "8560ac82-1f6d-4c70-976d-90cfeac721c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        monday feb ramallah februari wafa palestin lib...\n",
            "1        buffett politician dead wrong economi warren b...\n",
            "2        monday feb ramallah februari wafa govern japan...\n",
            "3        tuesday mar ramallah februari wafa govern japa...\n",
            "4        microsoft take six billion dollar android long...\n",
            "                               ...                        \n",
            "92803    stock rise investor key u economi ahead friday...\n",
            "92804    russian pm propos use conserv tough scenario a...\n",
            "92805    palestinian govern us foreign aid pay terroris...\n",
            "92806    palestin youth orchestra prepar first uk tour ...\n",
            "92807    sausalito businesswoman win microsoft window g...\n",
            "Name: title_headline, Length: 92808, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "JBWixxDnA5nR",
        "outputId": "b83ff886-bb74-4b7c-80fc-3388d8c03822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    IDLink                                  Title  \\\n",
              "0  80690.0                             monday feb   \n",
              "1  28854.0  buffett politician dead wrong economi   \n",
              "\n",
              "                                            Headline      Topic PublishDate  \\\n",
              "0  ramallah februari wafa palestin liber organ se...  palestine  2016-02-28   \n",
              "1  warren buffett messag presidenti candid other ...    economy  2016-02-28   \n",
              "\n",
              "   SentimentTitle  SentimentHeadline  Facebook  GooglePlus  LinkedIn  \\\n",
              "0        0.000000          -0.005906       1.0         1.0       1.0   \n",
              "1        0.051031          -0.037921       0.0         0.0       0.0   \n",
              "\n",
              "  PublishTime Weekday  Facebook_scaled  GooglePlus_scaled  LinkedIn_scaled  \\\n",
              "0    14:03:00  Sunday         -0.64969          -0.617774        -0.563154   \n",
              "1    19:17:00  Sunday          0.00000           0.000000         0.000000   \n",
              "\n",
              "  SentimentTitle_Category SentimentHeadline_Category Source_type  Hour  \\\n",
              "0                 neutral                   negative           D    14   \n",
              "1                positive                   negative           D    19   \n",
              "\n",
              "                                      title_headline  \n",
              "0  monday feb ramallah februari wafa palestin lib...  \n",
              "1  buffett politician dead wrong economi warren b...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ffa6411-86ae-49ea-bdae-9ebe4ba7857a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDLink</th>\n",
              "      <th>Title</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Topic</th>\n",
              "      <th>PublishDate</th>\n",
              "      <th>SentimentTitle</th>\n",
              "      <th>SentimentHeadline</th>\n",
              "      <th>Facebook</th>\n",
              "      <th>GooglePlus</th>\n",
              "      <th>LinkedIn</th>\n",
              "      <th>PublishTime</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>Facebook_scaled</th>\n",
              "      <th>GooglePlus_scaled</th>\n",
              "      <th>LinkedIn_scaled</th>\n",
              "      <th>SentimentTitle_Category</th>\n",
              "      <th>SentimentHeadline_Category</th>\n",
              "      <th>Source_type</th>\n",
              "      <th>Hour</th>\n",
              "      <th>title_headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>80690.0</td>\n",
              "      <td>monday feb</td>\n",
              "      <td>ramallah februari wafa palestin liber organ se...</td>\n",
              "      <td>palestine</td>\n",
              "      <td>2016-02-28</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.005906</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14:03:00</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>-0.64969</td>\n",
              "      <td>-0.617774</td>\n",
              "      <td>-0.563154</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "      <td>D</td>\n",
              "      <td>14</td>\n",
              "      <td>monday feb ramallah februari wafa palestin lib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28854.0</td>\n",
              "      <td>buffett politician dead wrong economi</td>\n",
              "      <td>warren buffett messag presidenti candid other ...</td>\n",
              "      <td>economy</td>\n",
              "      <td>2016-02-28</td>\n",
              "      <td>0.051031</td>\n",
              "      <td>-0.037921</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19:17:00</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "      <td>D</td>\n",
              "      <td>19</td>\n",
              "      <td>buffett politician dead wrong economi warren b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ffa6411-86ae-49ea-bdae-9ebe4ba7857a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ffa6411-86ae-49ea-bdae-9ebe4ba7857a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ffa6411-86ae-49ea-bdae-9ebe4ba7857a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff8181a7-d025-4d7e-a920-20475d1416e1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff8181a7-d025-4d7e-a920-20475d1416e1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff8181a7-d025-4d7e-a920-20475d1416e1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the news for SentimentTitle classification\n",
        "X_title = df['Title']\n",
        "y_title = df['SentimentTitle_Category']\n",
        "\n",
        "\n",
        "# Prepare the news for SentimentHeadline classification\n",
        "X_headline = df['Headline']\n",
        "y_headline = df['SentimentHeadline_Category']"
      ],
      "metadata": {
        "id": "jW78uWOWGGHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Splitting the data**"
      ],
      "metadata": {
        "id": "-qJ9xSdYXfhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data for SentimentTitle classification into training and testing sets\n",
        "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(X_title, y_title, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the data for SentimentHeadline classification into training and testing sets\n",
        "X_train_headline, X_test_headline, y_train_headline, y_test_headline = train_test_split(X_headline, y_headline, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "g9gVI4ZFGGEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TF-IDF Vectorization**"
      ],
      "metadata": {
        "id": "YgBbKYzdXa3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create separate TF-IDF vectorizers for each classification task\n",
        "# Title\n",
        "tfidf_vectorizer_title = TfidfVectorizer(max_features=10000, stop_words='english')\n",
        "X_train_tfidf_title = tfidf_vectorizer_title.fit_transform(X_train_title)\n",
        "X_test_tfidf_title = tfidf_vectorizer_title.transform(X_test_title)\n",
        "\n",
        "# Headline\n",
        "tfidf_vectorizer_headline = TfidfVectorizer(max_features=10000, stop_words='english')\n",
        "X_train_tfidf_headline = tfidf_vectorizer_headline.fit_transform(X_train_headline)\n",
        "X_test_tfidf_headline = tfidf_vectorizer_headline.transform(X_test_headline)"
      ],
      "metadata": {
        "id": "EravNMqYGF9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model Building**\n",
        "---"
      ],
      "metadata": {
        "id": "HMW67tLxXtb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Logistic Regression**"
      ],
      "metadata": {
        "id": "_h8L-fmIXOSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Title**"
      ],
      "metadata": {
        "id": "Gz5uaMb4XJYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Logistic Regression model\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model on the TF-IDF transformed training data\n",
        "clf.fit(X_train_tfidf_title, y_train_title)\n",
        "\n",
        "# Make predictions on the TF-IDF transformed test data\n",
        "y_pred_clf = clf.predict(X_test_tfidf_title)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_clf = accuracy_score(y_test_title, y_pred_clf)\n",
        "print(f'Accuracy: {accuracy_clf}')\n",
        "\n",
        "# Print classification report for more detailed metrics\n",
        "report_clf = classification_report(y_test_title, y_pred_clf)\n",
        "print('Classification Report:')\n",
        "print(report_clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL0cWyXbGp1Y",
        "outputId": "c6c0a40c-f1e3-4395-d961-82ac228966dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6612972740006465\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.68      0.74      0.71      7593\n",
            "     neutral       0.58      0.42      0.48      3742\n",
            "    positive       0.67      0.71      0.69      7227\n",
            "\n",
            "    accuracy                           0.66     18562\n",
            "   macro avg       0.64      0.62      0.63     18562\n",
            "weighted avg       0.66      0.66      0.66     18562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Headline**"
      ],
      "metadata": {
        "id": "b4glzer7XFAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Logistic Regression model\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model on the TF-IDF transformed training data\n",
        "clf.fit(X_train_tfidf_headline, y_train_headline)\n",
        "\n",
        "# Make predictions on the TF-IDF transformed test data\n",
        "y_pred_clf_head = clf.predict(X_test_tfidf_headline)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_clf_head = accuracy_score(y_test_headline, y_pred_clf_head)\n",
        "print(f'Accuracy: {accuracy_clf_head}')\n",
        "\n",
        "# Print classification report for more detailed metrics\n",
        "report_clf_head = classification_report(y_test_headline, y_pred_clf_head)\n",
        "print('Classification Report:')\n",
        "print(report_clf_head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKKQXD0cHf2h",
        "outputId": "cd794b3d-3356-4f75-e2a6-da9603a6b679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7143626764357289\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.81      0.77     10550\n",
            "     neutral       0.67      0.01      0.03       571\n",
            "    positive       0.68      0.63      0.65      7441\n",
            "\n",
            "    accuracy                           0.71     18562\n",
            "   macro avg       0.69      0.48      0.48     18562\n",
            "weighted avg       0.71      0.71      0.70     18562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Decision Tree**"
      ],
      "metadata": {
        "id": "P3-GdoboXSk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Title**"
      ],
      "metadata": {
        "id": "S_X-znMLXCwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Decision tree classifier model\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model on the TF-IDF transformed training data\n",
        "dt.fit(X_train_tfidf_title, y_train_title)\n",
        "\n",
        "# Make predictions on the TF-IDF transformed test data\n",
        "y_pred_dt = dt.predict(X_test_tfidf_title)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_dt = accuracy_score(y_test_title, y_pred_dt)\n",
        "print(f'Accuracy: {accuracy_dt}')\n",
        "\n",
        "# Print classification report for more detailed metrics\n",
        "report_dt = classification_report(y_test_title, y_pred_dt)\n",
        "print('Classification Report:')\n",
        "print(report_dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS3nsW8KGpx_",
        "outputId": "42f931b1-cde0-4a74-fafa-b8f42eab5090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6322055812951191\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.67      0.67      0.67      7593\n",
            "     neutral       0.51      0.51      0.51      3742\n",
            "    positive       0.65      0.66      0.66      7227\n",
            "\n",
            "    accuracy                           0.63     18562\n",
            "   macro avg       0.61      0.61      0.61     18562\n",
            "weighted avg       0.63      0.63      0.63     18562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Headline**"
      ],
      "metadata": {
        "id": "NlL9uYk2XBrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Decision tree classifier model\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model on the TF-IDF transformed training data\n",
        "dt.fit(X_train_tfidf_headline, y_train_headline)\n",
        "\n",
        "# Make predictions on the TF-IDF transformed test data\n",
        "y_pred_dt_head = dt.predict(X_test_tfidf_headline)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_dt_head = accuracy_score(y_test_headline, y_pred_dt_head)\n",
        "print(f'Accuracy: {accuracy_dt_head}')\n",
        "\n",
        "# Print classification report for more detailed metrics\n",
        "report_dt_head = classification_report(y_test_headline, y_pred_dt_head)\n",
        "print('Classification Report:')\n",
        "print(report_dt_head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMlskPQCIcmu",
        "outputId": "9c7706eb-8bef-48aa-e5c3-af15199aad2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6448658549725245\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.70      0.70     10550\n",
            "     neutral       0.25      0.19      0.22       571\n",
            "    positive       0.58      0.60      0.59      7441\n",
            "\n",
            "    accuracy                           0.64     18562\n",
            "   macro avg       0.51      0.50      0.50     18562\n",
            "weighted avg       0.64      0.64      0.64     18562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest**"
      ],
      "metadata": {
        "id": "nvzycP3UXVzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Title**"
      ],
      "metadata": {
        "id": "3Noor509W9RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Train the model on the TF-IDF transformed training data\n",
        "rf.fit(X_train_tfidf_title, y_train_title)\n",
        "\n",
        "# Make predictions on the TF-IDF transformed test data\n",
        "y_pred_rf = rf.predict(X_test_tfidf_title)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(y_test_title, y_pred_rf)\n",
        "print(f'Accuracy: {accuracy_rf}')\n",
        "\n",
        "# Print classification report for more detailed metrics\n",
        "report_rf = classification_report(y_test_title, y_pred_rf)\n",
        "print('Classification Report:')\n",
        "print(report_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHh4fZK2HPo4",
        "outputId": "1b8a900c-ef40-4572-93b7-b5a2b9509298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6958301907122078\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.71      0.76      0.73      7593\n",
            "     neutral       0.64      0.52      0.57      3742\n",
            "    positive       0.71      0.73      0.72      7227\n",
            "\n",
            "    accuracy                           0.70     18562\n",
            "   macro avg       0.68      0.67      0.67     18562\n",
            "weighted avg       0.69      0.70      0.69     18562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Headline**"
      ],
      "metadata": {
        "id": "9X3S6SZ0W8Cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Train the model on the TF-IDF transformed training data\n",
        "rf.fit(X_train_tfidf_headline, y_train_headline)\n",
        "\n",
        "# Make predictions on the TF-IDF transformed test data\n",
        "y_pred_rf_head = rf.predict(X_test_tfidf_headline)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf_head = accuracy_score(y_test_headline, y_pred_rf_head)\n",
        "print(f'Accuracy: {accuracy_rf_head}')\n",
        "\n",
        "# Print classification report for more detailed metrics\n",
        "report_rf_head = classification_report(y_test_headline, y_pred_rf_head)\n",
        "print('Classification Report:')\n",
        "print(report_rf_head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-DcIjyPHVFk",
        "outputId": "98c5c0c3-ad56-447a-b942-47cf0e5235fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.720558129511906\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.84      0.78     10550\n",
            "     neutral       0.80      0.14      0.24       571\n",
            "    positive       0.70      0.60      0.65      7441\n",
            "\n",
            "    accuracy                           0.72     18562\n",
            "   macro avg       0.74      0.53      0.56     18562\n",
            "weighted avg       0.72      0.72      0.71     18562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Zb2jMTFm42"
      },
      "source": [
        "#**Word Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdGOwGhaFm42"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Title**"
      ],
      "metadata": {
        "id": "Xve4DFGWWzFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKzy5zyrFm42",
        "outputId": "1ca16eae-e40d-429a-d39a-fb41322b39ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Accuracy: 0.5321\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-trained Google Word2Vec model\n",
        "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Get the dimension of the word embeddings\n",
        "embedding_size = word2vec_model.vector_size\n",
        "\n",
        "# Compute average word embeddings for each review\n",
        "X_train_embeddings = []\n",
        "\n",
        "for review in X_train_title:\n",
        "    words = review.split()\n",
        "    embeddings = [word2vec_model[word] for word in words if word in word2vec_model]\n",
        "    if embeddings:\n",
        "        avg_embedding = sum(embeddings) / len(embeddings)\n",
        "        X_train_embeddings.append(avg_embedding)\n",
        "    else:\n",
        "        # Handle the case when no embeddings are available\n",
        "        X_train_embeddings.append([0.0] * embedding_size)\n",
        "\n",
        "X_test_embeddings = []\n",
        "\n",
        "for review in X_test_title:\n",
        "    words = review.split()\n",
        "    embeddings = [word2vec_model[word] for word in words if word in word2vec_model]\n",
        "    if embeddings:\n",
        "        avg_embedding = sum(embeddings) / len(embeddings)\n",
        "        X_test_embeddings.append(avg_embedding)\n",
        "    else:\n",
        "        # Handle the case when no embeddings are available\n",
        "        X_test_embeddings.append([0.0] * embedding_size)\n",
        "\n",
        "# Train Logistic Regression on average embeddings\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_embeddings, y_train_title)\n",
        "y_pred = lr.predict(X_test_embeddings)\n",
        "\n",
        "# Calculate accuracy and report\n",
        "accuracy = accuracy_score(y_test_title, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Headline**"
      ],
      "metadata": {
        "id": "-NIvOgS8W1R2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0mI_FeUFm42",
        "outputId": "8cbd4ec1-fe95-4587-b0c0-99d2b40c1a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6175\n"
          ]
        }
      ],
      "source": [
        "# Get the dimension of the word embeddings\n",
        "embedding_size = word2vec_model.vector_size\n",
        "\n",
        "# Compute average word embeddings for each review\n",
        "X_train_embeddings = []\n",
        "\n",
        "for review in X_train_headline:\n",
        "    words = review.split()\n",
        "    embeddings = [word2vec_model[word] for word in words if word in word2vec_model]\n",
        "    if embeddings:\n",
        "        avg_embedding = sum(embeddings) / len(embeddings)\n",
        "        X_train_embeddings.append(avg_embedding)\n",
        "    else:\n",
        "        # Handle the case when no embeddings are available\n",
        "        X_train_embeddings.append([0.0] * embedding_size)\n",
        "\n",
        "X_test_embeddings = []\n",
        "\n",
        "for review in X_test_headline:\n",
        "    words = review.split()\n",
        "    embeddings = [word2vec_model[word] for word in words if word in word2vec_model]\n",
        "    if embeddings:\n",
        "        avg_embedding = sum(embeddings) / len(embeddings)\n",
        "        X_test_embeddings.append(avg_embedding)\n",
        "    else:\n",
        "        # Handle the case when no embeddings are available\n",
        "        X_test_embeddings.append([0.0] * embedding_size)\n",
        "\n",
        "# Train Logistic Regression on average embeddings\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_embeddings, y_train_headline)\n",
        "y_pred = lr.predict(X_test_embeddings)\n",
        "\n",
        "# Calculate accuracy and report\n",
        "accuracy = accuracy_score(y_test_headline, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vomimT53Fm43",
        "outputId": "240ffdbd-7c95-4098-9d3b-dc911c02f47b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "[==================================================] 100.0% 252.1/252.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained GloVe models with different dimensions\n",
        "glove_50d = api.load(\"glove-wiki-gigaword-50\")\n",
        "glove_100d = api.load(\"glove-wiki-gigaword-100\")\n",
        "glove_200d = api.load(\"glove-wiki-gigaword-200\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Title**"
      ],
      "metadata": {
        "id": "pSt36A7hW4IV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE8Hg6dqFm44",
        "outputId": "ed23b521-bf3d-4912-f0b0-a72aa29a0716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (50D): 0.4761\n",
            "Accuracy (100D): 0.4976\n",
            "Accuracy (200D): 0.5134\n"
          ]
        }
      ],
      "source": [
        "# Compute average word embeddings for each review\n",
        "def compute_avg_embedding(review, model):\n",
        "    words = review.split()\n",
        "    embeddings = [model[word] for word in words if word in model]\n",
        "    if embeddings:\n",
        "        avg_embedding = sum(embeddings) / len(embeddings)\n",
        "        return avg_embedding\n",
        "    else:\n",
        "        return [0.0] * model.vector_size\n",
        "\n",
        "X_train_embeddings_50d = [compute_avg_embedding(review, glove_50d) for review in X_train_title]\n",
        "X_test_embeddings_50d = [compute_avg_embedding(review, glove_50d) for review in X_test_title]\n",
        "\n",
        "X_train_embeddings_100d = [compute_avg_embedding(review, glove_100d) for review in X_train_title]\n",
        "X_test_embeddings_100d = [compute_avg_embedding(review, glove_100d) for review in X_test_title]\n",
        "\n",
        "X_train_embeddings_200d = [compute_avg_embedding(review, glove_200d) for review in X_train_title]\n",
        "X_test_embeddings_200d = [compute_avg_embedding(review, glove_200d) for review in X_test_title]\n",
        "\n",
        "# Train Logistic Regression on average embeddings and report accuracy\n",
        "def train_and_report_accuracy(X_train_embeddings, X_test_embeddings):\n",
        "    lr = LogisticRegression(max_iter=1000)\n",
        "    lr.fit(X_train_embeddings, y_train_title)\n",
        "    y_pred = lr.predict(X_test_embeddings)\n",
        "    accuracy = accuracy_score(y_test_title, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "accuracy_50d = train_and_report_accuracy(X_train_embeddings_50d, X_test_embeddings_50d)\n",
        "accuracy_100d = train_and_report_accuracy(X_train_embeddings_100d, X_test_embeddings_100d)\n",
        "accuracy_200d = train_and_report_accuracy(X_train_embeddings_200d, X_test_embeddings_200d)\n",
        "\n",
        "print(f\"Accuracy (50D): {accuracy_50d:.4f}\")\n",
        "print(f\"Accuracy (100D): {accuracy_100d:.4f}\")\n",
        "print(f\"Accuracy (200D): {accuracy_200d:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Headline**"
      ],
      "metadata": {
        "id": "vjccuIQRW3D1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERFVjZNiFm44",
        "outputId": "7dccdaed-a67c-4738-903a-4ede2e443e3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (50D): 0.5784\n",
            "Accuracy (100D): 0.5907\n",
            "Accuracy (200D): 0.6056\n"
          ]
        }
      ],
      "source": [
        "# Compute average word embeddings for each review\n",
        "def compute_avg_embedding(review, model):\n",
        "    words = review.split()\n",
        "    embeddings = [model[word] for word in words if word in model]\n",
        "    if embeddings:\n",
        "        avg_embedding = sum(embeddings) / len(embeddings)\n",
        "        return avg_embedding\n",
        "    else:\n",
        "        return [0.0] * model.vector_size\n",
        "\n",
        "X_train_embeddings_50d = [compute_avg_embedding(review, glove_50d) for review in X_train_headline]\n",
        "X_test_embeddings_50d = [compute_avg_embedding(review, glove_50d) for review in X_test_headline]\n",
        "\n",
        "X_train_embeddings_100d = [compute_avg_embedding(review, glove_100d) for review in X_train_headline]\n",
        "X_test_embeddings_100d = [compute_avg_embedding(review, glove_100d) for review in X_test_headline]\n",
        "\n",
        "X_train_embeddings_200d = [compute_avg_embedding(review, glove_200d) for review in X_train_headline]\n",
        "X_test_embeddings_200d = [compute_avg_embedding(review, glove_200d) for review in X_test_headline]\n",
        "\n",
        "# Train Logistic Regression on average embeddings and report accuracy\n",
        "def train_and_report_accuracy(X_train_embeddings, X_test_embeddings):\n",
        "    lr = LogisticRegression(max_iter=1000)\n",
        "    lr.fit(X_train_embeddings, y_train_headline)\n",
        "    y_pred = lr.predict(X_test_embeddings)\n",
        "    accuracy = accuracy_score(y_test_headline, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "accuracy_50d = train_and_report_accuracy(X_train_embeddings_50d, X_test_embeddings_50d)\n",
        "accuracy_100d = train_and_report_accuracy(X_train_embeddings_100d, X_test_embeddings_100d)\n",
        "accuracy_200d = train_and_report_accuracy(X_train_embeddings_200d, X_test_embeddings_200d)\n",
        "\n",
        "print(f\"Accuracy (50D): {accuracy_50d:.4f}\")\n",
        "print(f\"Accuracy (100D): {accuracy_100d:.4f}\")\n",
        "print(f\"Accuracy (200D): {accuracy_200d:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8NlQ0nXFm45"
      },
      "source": [
        "#**Deep Learning Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB96n695Fm45"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout,SimpleRNN\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNguv_7xFm45"
      },
      "outputs": [],
      "source": [
        "# Define parameters for the RNN model\n",
        "vocab_size = 10000\n",
        "max_sequence_length = 100\n",
        "embedding_dim = 100\n",
        "num_epochs = 5\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_title)\n",
        "sequences = tokenizer.texts_to_sequences(X_train_title)\n",
        "\n",
        "# Pad sequences to ensure they have the same length\n",
        "X_train_padded = pad_sequences(sequences, maxlen=max_sequence_length, truncating='post', padding='post')\n",
        "\n",
        "# Encode target labels using one-hot encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train_title)\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEXIjcyeFm45"
      },
      "source": [
        "#**RNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Title**"
      ],
      "metadata": {
        "id": "3Mtq_ZwgWkAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApqsZqMkFm46",
        "outputId": "ebfda6a2-bb13-43b6-aa64-7e25f620cc5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1857/1857 - 71s - loss: 1.0601 - accuracy: 0.4041 - val_loss: 1.0594 - val_accuracy: 0.3966 - 71s/epoch - 38ms/step\n",
            "Epoch 2/5\n",
            "1857/1857 - 67s - loss: 1.0577 - accuracy: 0.4000 - val_loss: 1.0592 - val_accuracy: 0.3966 - 67s/epoch - 36ms/step\n",
            "Epoch 3/5\n",
            "1857/1857 - 79s - loss: 1.0575 - accuracy: 0.4015 - val_loss: 1.0637 - val_accuracy: 0.3966 - 79s/epoch - 43ms/step\n",
            "Epoch 4/5\n",
            "1857/1857 - 66s - loss: 1.0591 - accuracy: 0.4028 - val_loss: 1.0599 - val_accuracy: 0.3920 - 66s/epoch - 36ms/step\n",
            "Epoch 5/5\n",
            "1857/1857 - 67s - loss: 1.0577 - accuracy: 0.4008 - val_loss: 1.0570 - val_accuracy: 0.4084 - 67s/epoch - 36ms/step\n",
            "581/581 [==============================] - 6s 10ms/step\n",
            "Accuracy: 0.40884602952268073\n"
          ]
        }
      ],
      "source": [
        "# Create the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(64, return_sequences=True))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_padded, y_train_one_hot, epochs=num_epochs, validation_split=0.2, batch_size=32, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test_title)\n",
        "X_test_padded = pad_sequences(sequences_test, maxlen=max_sequence_length, truncating='post', padding='post')\n",
        "y_pred = model.predict(X_test_padded)\n",
        "\n",
        "# Convert one-hot encoded predictions to labels\n",
        "y_pred_labels_encoded = np.argmax(y_pred, axis=1)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_labels_encoded)\n",
        "\n",
        "# Encode test labels and convert to one-hot encoding\n",
        "y_test_encoded = label_encoder.transform(y_test_title)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=3)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = np.mean(y_pred_labels_encoded == y_test_encoded)\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Headline**"
      ],
      "metadata": {
        "id": "pxiYMTD-WimB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIQhLeyTFm46",
        "outputId": "fca82085-5d57-4363-e137-eceae661bd83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1857/1857 - 68s - loss: 1.0621 - accuracy: 0.4004 - val_loss: 1.0656 - val_accuracy: 0.3966 - 68s/epoch - 36ms/step\n",
            "Epoch 2/5\n",
            "1857/1857 - 67s - loss: 1.0589 - accuracy: 0.4012 - val_loss: 1.0595 - val_accuracy: 0.3966 - 67s/epoch - 36ms/step\n",
            "Epoch 3/5\n",
            "1857/1857 - 66s - loss: 1.0579 - accuracy: 0.4019 - val_loss: 1.0578 - val_accuracy: 0.3947 - 66s/epoch - 36ms/step\n",
            "Epoch 4/5\n",
            "1857/1857 - 66s - loss: 1.0568 - accuracy: 0.4046 - val_loss: 1.0572 - val_accuracy: 0.3966 - 66s/epoch - 36ms/step\n",
            "Epoch 5/5\n",
            "1857/1857 - 67s - loss: 1.0575 - accuracy: 0.4041 - val_loss: 1.0625 - val_accuracy: 0.3966 - 67s/epoch - 36ms/step\n",
            "581/581 [==============================] - 5s 9ms/step\n",
            "Accuracy: 0.5683654778579894\n"
          ]
        }
      ],
      "source": [
        "# Create the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(64, return_sequences=True))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_padded, y_train_one_hot, epochs=num_epochs, validation_split=0.2, batch_size=32, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test_headline)\n",
        "X_test_padded = pad_sequences(sequences_test, maxlen=max_sequence_length, truncating='post', padding='post')\n",
        "y_pred = model.predict(X_test_padded)\n",
        "\n",
        "# Convert one-hot encoded predictions to labels\n",
        "y_pred_labels_encoded = np.argmax(y_pred, axis=1)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_labels_encoded)\n",
        "\n",
        "# Encode test labels and convert to one-hot encoding\n",
        "y_test_encoded = label_encoder.transform(y_test_headline)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=3)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = np.mean(y_pred_labels_encoded == y_test_encoded)\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAYXCbGvFm46"
      },
      "source": [
        "#**LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Title**"
      ],
      "metadata": {
        "id": "D_r2_fOFWbL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEJlR-nXFm47",
        "outputId": "0269493b-ec0d-491a-c239-3086c619b576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1857/1857 - 166s - loss: 1.0560 - accuracy: 0.4043 - val_loss: 1.0575 - val_accuracy: 0.3966 - 166s/epoch - 90ms/step\n",
            "Epoch 2/5\n",
            "1857/1857 - 166s - loss: 1.0552 - accuracy: 0.4057 - val_loss: 1.0578 - val_accuracy: 0.3966 - 166s/epoch - 89ms/step\n",
            "Epoch 3/5\n",
            "1857/1857 - 164s - loss: 1.0551 - accuracy: 0.4078 - val_loss: 1.0585 - val_accuracy: 0.3966 - 164s/epoch - 88ms/step\n",
            "Epoch 4/5\n",
            "1857/1857 - 161s - loss: 1.0551 - accuracy: 0.4060 - val_loss: 1.0575 - val_accuracy: 0.3966 - 161s/epoch - 87ms/step\n",
            "Epoch 5/5\n",
            "1857/1857 - 163s - loss: 1.0549 - accuracy: 0.4069 - val_loss: 1.0571 - val_accuracy: 0.3966 - 163s/epoch - 88ms/step\n",
            "581/581 [==============================] - 13s 21ms/step\n",
            "Accuracy: 0.4090615235427217\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_padded, y_train_one_hot, epochs=num_epochs, validation_split=0.2, batch_size=32, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test_title)\n",
        "X_test_padded = pad_sequences(sequences_test, maxlen=max_sequence_length, truncating='post', padding='post')\n",
        "y_pred = model.predict(X_test_padded)\n",
        "\n",
        "# Convert one-hot encoded predictions to labels\n",
        "y_pred_labels_encoded = np.argmax(y_pred, axis=1)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_labels_encoded)\n",
        "\n",
        "# Encode test labels and convert to one-hot encoding\n",
        "y_test_encoded = label_encoder.transform(y_test_title)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=3)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = np.mean(y_pred_labels_encoded == y_test_encoded)\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Headline**"
      ],
      "metadata": {
        "id": "E45xbCm_Wd-_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rR6XxYgFm47",
        "outputId": "b47a043d-42a9-4126-9a75-1e40ca1ed8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1857/1857 - 169s - loss: 1.0560 - accuracy: 0.4050 - val_loss: 1.0573 - val_accuracy: 0.3966 - 169s/epoch - 91ms/step\n",
            "Epoch 2/5\n",
            "1857/1857 - 168s - loss: 1.0554 - accuracy: 0.4059 - val_loss: 1.0571 - val_accuracy: 0.3966 - 168s/epoch - 91ms/step\n",
            "Epoch 3/5\n",
            "1857/1857 - 163s - loss: 1.0551 - accuracy: 0.4071 - val_loss: 1.0571 - val_accuracy: 0.3966 - 163s/epoch - 88ms/step\n",
            "Epoch 4/5\n",
            "1857/1857 - 161s - loss: 1.0550 - accuracy: 0.4066 - val_loss: 1.0582 - val_accuracy: 0.3966 - 161s/epoch - 87ms/step\n",
            "Epoch 5/5\n",
            "1857/1857 - 161s - loss: 1.0551 - accuracy: 0.4063 - val_loss: 1.0569 - val_accuracy: 0.3966 - 161s/epoch - 87ms/step\n",
            "581/581 [==============================] - 12s 20ms/step\n",
            "Accuracy: 0.5683654778579894\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_padded, y_train_one_hot, epochs=num_epochs, validation_split=0.2, batch_size=32, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test_headline)\n",
        "X_test_padded = pad_sequences(sequences_test, maxlen=max_sequence_length, truncating='post', padding='post')\n",
        "y_pred = model.predict(X_test_padded)\n",
        "\n",
        "# Convert one-hot encoded predictions to labels\n",
        "y_pred_labels_encoded = np.argmax(y_pred, axis=1)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_labels_encoded)\n",
        "\n",
        "# Encode test labels and convert to one-hot encoding\n",
        "y_test_encoded = label_encoder.transform(y_test_headline)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=3)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = np.mean(y_pred_labels_encoded == y_test_encoded)\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMp6AEnWSAbb"
      },
      "source": [
        "##**BiLSTM**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Title**"
      ],
      "metadata": {
        "id": "S0xIi9KPWQdz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCGq1ZZKSAbc"
      },
      "outputs": [],
      "source": [
        "# Create the BiLstm model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iFjc_EuSAbc",
        "outputId": "23184ae7-191f-4b8a-dcbe-d94e3a2efe92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1857/1857 - 320s - loss: 0.8458 - accuracy: 0.6195 - val_loss: 0.7708 - val_accuracy: 0.6743 - 320s/epoch - 172ms/step\n",
            "Epoch 2/5\n",
            "1857/1857 - 307s - loss: 0.7003 - accuracy: 0.7154 - val_loss: 0.7535 - val_accuracy: 0.6831 - 307s/epoch - 165ms/step\n",
            "Epoch 3/5\n",
            "1857/1857 - 311s - loss: 0.6114 - accuracy: 0.7572 - val_loss: 0.7850 - val_accuracy: 0.6838 - 311s/epoch - 167ms/step\n",
            "Epoch 4/5\n",
            "1857/1857 - 306s - loss: 0.5345 - accuracy: 0.7890 - val_loss: 0.8152 - val_accuracy: 0.6852 - 306s/epoch - 165ms/step\n",
            "Epoch 5/5\n",
            "1857/1857 - 308s - loss: 0.4658 - accuracy: 0.8151 - val_loss: 0.9050 - val_accuracy: 0.6827 - 308s/epoch - 166ms/step\n",
            "581/581 [==============================] - 23s 38ms/step\n",
            "Accuracy: 0.6786984161189527\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_padded, y_train_one_hot, epochs=num_epochs, validation_split=0.2, batch_size=32, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test_title)\n",
        "X_test_padded = pad_sequences(sequences_test, maxlen=max_sequence_length, truncating='post', padding='post')\n",
        "y_pred = model.predict(X_test_padded)\n",
        "\n",
        "# Convert one-hot encoded predictions to labels\n",
        "y_pred_labels_encoded = np.argmax(y_pred, axis=1)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_labels_encoded)\n",
        "\n",
        "# Encode test labels and convert to one-hot encoding\n",
        "y_test_encoded = label_encoder.transform(y_test_title)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=3)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = np.mean(y_pred_labels_encoded == y_test_encoded)\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Headline**"
      ],
      "metadata": {
        "id": "FyqyonLtWYaW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef9EEGQQSAbc"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_headline)\n",
        "sequences = tokenizer.texts_to_sequences(X_train_headline)\n",
        "\n",
        "# Pad sequences to ensure they have the same length\n",
        "X_train_padded = pad_sequences(sequences, maxlen=max_sequence_length, truncating='post', padding='post')\n",
        "\n",
        "# Encode target labels using one-hot encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train_headline)\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEa7Z2pfSAbc"
      },
      "outputs": [],
      "source": [
        "# Create the BiLstm model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boCKShaJSAbd",
        "outputId": "60df5abe-2f0f-4e03-dea7-1912ada86967",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1857/1857 - 315s - loss: 0.6815 - accuracy: 0.6796 - val_loss: 0.6288 - val_accuracy: 0.7179 - 315s/epoch - 170ms/step\n",
            "Epoch 2/5\n",
            "1857/1857 - 308s - loss: 0.5701 - accuracy: 0.7518 - val_loss: 0.6272 - val_accuracy: 0.7221 - 308s/epoch - 166ms/step\n",
            "Epoch 3/5\n",
            "1857/1857 - 307s - loss: 0.4980 - accuracy: 0.7893 - val_loss: 0.6583 - val_accuracy: 0.7151 - 307s/epoch - 165ms/step\n",
            "Epoch 4/5\n",
            "1857/1857 - 307s - loss: 0.4267 - accuracy: 0.8215 - val_loss: 0.7096 - val_accuracy: 0.7132 - 307s/epoch - 165ms/step\n",
            "Epoch 5/5\n",
            "1857/1857 - 307s - loss: 0.3606 - accuracy: 0.8529 - val_loss: 0.7716 - val_accuracy: 0.7098 - 307s/epoch - 165ms/step\n",
            "581/581 [==============================] - 22s 36ms/step\n",
            "Accuracy: 0.7070897532593471\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_padded, y_train_one_hot, epochs=num_epochs, validation_split=0.2, batch_size=32, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test_headline)\n",
        "X_test_padded = pad_sequences(sequences_test, maxlen=max_sequence_length, truncating='post', padding='post')\n",
        "y_pred = model.predict(X_test_padded)\n",
        "\n",
        "# Convert one-hot encoded predictions to labels\n",
        "y_pred_labels_encoded = np.argmax(y_pred, axis=1)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_labels_encoded)\n",
        "\n",
        "# Encode test labels and convert to one-hot encoding\n",
        "y_test_encoded = label_encoder.transform(y_test_headline)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=3)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = np.mean(y_pred_labels_encoded == y_test_encoded)\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model Performance**\n",
        "----\n",
        "*Sentiment Analysis:*\n",
        "\n",
        "- Random Forest model performed the best and gave the Accuracy score of: 70% on Title and 72% on Headline\n",
        "\n",
        "\n",
        "- While RNN and LSTM model performed very poorly, BiLSTM showed significant improvement and gave much better results (accuracy score of: 68% on Title and 71% on Headline )\n"
      ],
      "metadata": {
        "id": "F0St16pqVHFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Conclusions**\n",
        "---\n",
        "\n",
        "**Business Problem Solutions:**\n",
        "\n",
        "> **Based on inferences from EDA, it is recommended to post:**\n",
        "-\tNews on Facebook on the topic Obama between 14:00 till mid-night, on a Saturday, to improve the chances of it being popular.\n",
        "-\tNews on LinkedIn on the topic Microsoft, on a Monday, to improve the chances of it being popular.\n",
        "\n",
        "> **Based on inferences from the models:**\n",
        "-\tBefore publishing any news, they can check its popularity on a particular platform and how it will be perceived on the platform.\n",
        "-\tHigher the popularity scores the better it is. And though negative sentiment news are seen to be more popular, news with positive sentiment would tend to have a greater impact.\n"
      ],
      "metadata": {
        "id": "G-2v7yzqUp4_"
      }
    }
  ]
}